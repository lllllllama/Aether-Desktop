#!/usr/bin/env python3
"""æµ‹è¯•OpenRouterçš„å…è´¹æ¨¡å‹å¯ç”¨æ€§"""

import requests
from utils.config_manager import get_config

def test_openrouter_models():
    """æµ‹è¯•OpenRouterçš„å…è´¹æ¨¡å‹"""
    config = get_config()
    api_key = config.get("AI_CONFIG", "openrouter_api_key", fallback="").strip()
    
    print("ğŸš€ æµ‹è¯•OpenRouterå…è´¹æ¨¡å‹å¯ç”¨æ€§")
    print("=" * 50)
    
    # å¸¸è§çš„å…è´¹æ¨¡å‹åˆ—è¡¨
    free_models = [
        "deepseek-ai/deepseek-v3",
        "deepseek-ai/deepseek-v2.5:free",
        "deepseek-ai/deepseek-chat:free",
        "meta-llama/llama-3.1-8b-instruct:free",
        "microsoft/phi-3-mini-128k-instruct:free",
        "google/gemma-7b-it:free",
        "qwen/qwen-2-7b-instruct:free",
        "mistralai/mistral-7b-instruct:free"
    ]
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://aether-desktop.com",
        "X-Title": "Aether Desktop"
    }
    
    payload_template = {
        "messages": [{"role": "user", "content": "Hello"}],
        "max_tokens": 10
    }
    
    working_models = []
    
    for model in free_models:
        print(f"ğŸ“¡ æµ‹è¯•æ¨¡å‹: {model}")
        
        payload = payload_template.copy()
        payload["model"] = model
        
        try:
            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=10
            )
            
            if response.status_code == 200:
                print(f"  âœ… {model} - å¯ç”¨")
                working_models.append(model)
            else:
                print(f"  âŒ {model} - é”™è¯¯: {response.status_code}")
                if response.status_code == 400:
                    error_data = response.json()
                    print(f"     è¯¦æƒ…: {error_data.get('error', {}).get('message', 'Unknown error')}")
                
        except Exception as e:
            print(f"  âŒ {model} - å¼‚å¸¸: {e}")
    
    print("\nğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    print(f"âœ… å¯ç”¨æ¨¡å‹æ•°é‡: {len(working_models)}")
    
    if working_models:
        print("ğŸ¯ æ¨èä½¿ç”¨çš„æ¨¡å‹:")
        for model in working_models[:3]:  # æ˜¾ç¤ºå‰3ä¸ªå¯ç”¨æ¨¡å‹
            print(f"  - {model}")
        
        return working_models[0]  # è¿”å›ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
    else:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„å…è´¹æ¨¡å‹")
        return None

if __name__ == "__main__":
    best_model = test_openrouter_models()
    if best_model:
        print(f"\nğŸ”§ å»ºè®®é…ç½®æ¨¡å‹: {best_model}")
    else:
        print("\nâš ï¸  å»ºè®®ä½¿ç”¨Groq APIä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")
